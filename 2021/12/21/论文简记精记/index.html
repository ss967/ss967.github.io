<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文简记 | 星空Blog</title><meta name="keywords" content="机器学习,论文笔记"><meta name="author" content="ss967"><meta name="copyright" content="ss967"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="对后面看到的一些经典的文章或者创新性和思路比较好的文章做一个简要的记录，主要记一些文章中关键内容和核心思路所以不会记得很详细。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文简记">
<meta property="og:url" content="http://ss967.github.io/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/index.html">
<meta property="og:site_name" content="星空Blog">
<meta property="og:description" content="对后面看到的一些经典的文章或者创新性和思路比较好的文章做一个简要的记录，主要记一些文章中关键内容和核心思路所以不会记得很详细。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://ss967.github.io/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/cover.jpeg">
<meta property="article:published_time" content="2021-12-21T00:30:48.000Z">
<meta property="article:modified_time" content="2022-02-26T23:57:13.609Z">
<meta property="article:author" content="ss967">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="论文笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ss967.github.io/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/cover.jpeg"><link rel="shortcut icon" href="/img/logo.ico"><link rel="canonical" href="http://ss967.github.io/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?506834e66449f901499a22592120422e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#9370DB","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文简记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-27 07:57:13'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2928498_ppl07sthm9q.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/rss2.xml" title="星空Blog" type="application/rss+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/top.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单列表</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/cover.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">星空Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单列表</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文简记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-21T00:30:48.000Z" title="发表于 2021-12-21 08:30:48">2021-12-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-26T23:57:13.609Z" title="更新于 2022-02-27 07:57:13">2022-02-27</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文简记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision">CLIP:Learning Transferable Visual Models From Natural Language Supervision</h2>
<p>（2022.2.13）</p>
<blockquote>
<p>简要介绍</p>
</blockquote>
<p><strong>论文连接</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.00020.pdf">https://arxiv.org/pdf/2103.00020.pdf</a></p>
<p><strong>GitHub代码地址</strong>：<a target="_blank" rel="noopener" href="https://github.com/OpenAI/CLIP">https://github.com/OpenAI/CLIP</a></p>
<p><strong>简要描述</strong>：作者认为像用类似ImageNet数据集中有1000个固定类别做预训练，限制了模型做迁移的泛化性和扩展性。因此作者设计了一个新的预训练任务——通过图片直接预测对应的文本，为此作者团队从网上爬取大量的&lt;图片，文本&gt;数据样本形成了一个包含4亿样本的数据集。通过该数据集做预训练最终在不用一张imageNet数据集中图片(Zero-shot)的情况下可以和ResNet-50打成平手（top-1准确率76.2%）且在相关的下游任务中，zero-shot有更好的表现</p>
<blockquote>
<p>关键性的概念及内容</p>
</blockquote>
<ul>
<li>模型迁移学习过程
<ul>
<li>首先预训练阶段，对样本中的文本和图片分别进行编码。这里的编码器可以是ResNet-50这种卷积神经网络，也可以是Transformer这种。论文中效果最好的是采用的 ViT-L/14@336px这一模型。图中主对角线就是正例，其余特征的结合均为反例</li>
<li>将预训练好的模型迁移到新的任务上时，可以先进行简单的提示工程。如果是imageNet的话就是将一千个类别变成一千句话然后进行特征提取。提示工程具体来说就是假设有一个数据集中都是食物，那么第二步中就可以是a food photo of {object}。由于在预训练过程中模型是真的学到了图片对应的语义信息，因此这样的语义提示会有很好的效果。</li>
<li>如果是采用zero-shot模式的话，就直接对图片进行特征提取，同前面的文字特征进行结合的到最终的结果</li>
</ul>
</li>
</ul>
<p><img src="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/image-20220213122610415.png" alt="image-20220213122610415"></p>
<ul>
<li>
<p>迁移学习的形式</p>
<ul>
<li>
<p>zero-shot  : 在不用新数据集中任何一个样本的情况下进行迁移的形式</p>
</li>
<li>
<p>few-shot：仅对新数据集中每类使用少量的样本进行微调的过程</p>
</li>
<li>
<p>linear-probe： 将预训练的主干网络中的参数冻住，然后用全部新的数据集对尾部的分类或者具体任务进行微调的过程</p>
</li>
</ul>
</li>
<li>
<p>zero-shot是一个比较显眼的成果，但实际上论文中linear-probe的效果才是真正令人惊艳的，真正意义上能应用到更多的领域</p>
</li>
</ul>
<blockquote>
<p>个人的一些想法</p>
</blockquote>
<ul>
<li>我用冰墩墩和鞭炮做了一个简单的尝试，可以看到模型99.9%的认为这是一个熊猫，甚至于我把英文换成拼音xiongmao它也基本认定和这个图片有关（0.95）。还有就是在用鞭炮图片的时候我用中文它也有0.85认为和图片有关系。所以我很好奇是因为作者团队所创建的数据集过于庞大真的囊括大部分情况使得模型准确率如此高，还是说模型真的学到了文本和图片中的语义信息。</li>
</ul>
<p><img src="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/image-20220213143030191.png" alt="image-20220213143030191"></p>
<ul>
<li>作者自己在局限性章节指出，他们选用这些数据集做实验虽然数量很多，但是实验次数多了以后难免引入部分过拟合。模型的扩展性和泛化性需要进一步探究。</li>
<li>是否可以利用医学图像区域分割的数据集对该模型进行linear-probe。本身医学图像的数据集普遍都比较小，该模型在zero-shot和few-shot都有非常不错的表现，如果能够通过linear=probe进行微调将模型迁移到医学图像分割问题上感觉是个人感觉是可以取得不错的效果的。</li>
</ul>
<h2 id="ConvNeXt：A-ConvNet-for-the-2020s">ConvNeXt：A ConvNet for the 2020s</h2>
<p>（2022.2.16）</p>
<blockquote>
<p>简要介绍</p>
</blockquote>
<p><strong>论文连接</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.03545v1.pdf">https://arxiv.org/pdf/2201.03545v1.pdf</a></p>
<p><strong>GitHub代码地址</strong>： <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/ConvNeXt">https://github.com/facebookresearch/ConvNeXt</a></p>
<p><strong>简要描述</strong>：近几年随着VIT和Swin-Transformer的出现，相比于卷积神经网络（Conv），Transformer系列的架构在许多视觉任务上都表现的十分突出，因此研究人员普遍都认同Transformer这种结构在本质上优于Conv，能够在大规模参数的情况下得到更优异的成果。但作者团队却认为现阶段的transformer或者conv+transformer本质上都是相同的，造成效果不同的原因是优化策略，所以这篇论文就按照swin-transformer中的思路对resnet进行了充分的优化，最终在ImageNet数据集上取得和swin-Transformer同样的结果（top-1准确率：87.8%），在下游任务中基本都略优于transformer。</p>
<p>参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37541097/article/details/122556545?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164499362916780269849296%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164499362916780269849296&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-122556545.first_rank_v2_pc_rank_v29&amp;utm_term=convnext&amp;spm=1018.2226.3001.4187">ConvNeXt网络详解</a></p>
<blockquote>
<p>核心内容</p>
</blockquote>
<p>基本上这张图片就可以算是整篇论文的核心</p>
<p><img src="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/image-20220216150325775.png" alt="image-20220216150325775"></p>
<ul>
<li><strong>Macro design</strong>
<ul>
<li><strong>stage ratio</strong>, 作者从宏观角度发现ResNet-50中模块堆叠比例是(3,4,6,3)，但在swin-T中是(1,1,3,1)，在大型的swin-T甚至达到(1,1,9,1)，因此将ResNet中堆叠比例修改成(3,3,9,3)。准确率由78.8%提升到79.4%</li>
<li><strong>Changing stem to “Patchify”</strong>，在transformer中通常是使用不重叠的卷积层进行下采样（卷积核大小=步长），swin-T中使用的ks=4x4,stride=4，因此修改后的ResNet也采用该方式进行下采样。准确率提升了0.1%到79.5%，这步个人感觉意义不大更多是为了跟swin-T保持一致。</li>
</ul>
</li>
<li><strong>ResNeXt-ify</strong>，这一步主要是借鉴了ResNeXt中组卷积可以降低计算量提高准确率，将原始ResNet中瓶颈结构的3x3替换成组卷积。作者觉得<code>depthwise convolution</code>和<code>self-attention</code>中的加权求和操作类似，因此将dw conv的组数设置和通道数相同，最后准确率提升到80.5%
<ul>
<li>dw conv 和pw conv 含义作用可以参考这篇文章： <a target="_blank" rel="noopener" href="https://blog.csdn.net/tintinetmilou/article/details/81607721">https://blog.csdn.net/tintinetmilou/article/details/81607721</a></li>
</ul>
</li>
<li><strong>Inverted Bottleneck</strong>, 反瓶颈结构。在原始的ResNet中采用（大-小-大)的形式减少计算量，但是后面有人认为这样会损失空间信息应该采用图3 b中（小-大-小）的形式（b中最后的1x1应该是384=&gt;96），Transformer中MLP也有类似的设计，所以最后修改的ResNet采用了图4中所示的结构。最后准确率提升到80.6%</li>
</ul>
<p><img src="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/image-20220216160856740.png" alt="image-20220216160856740"></p>
<ul>
<li><strong>Large kernel</strong>, 自VGGNet后基本上卷积神经网络都采用的小卷积核(3x3)，但在transformer中大多都采用很大的卷积核，所以这里也同样进行效仿
<ul>
<li><strong>Moving up depthwise conv layer</strong>，把dw conv移动到1x1卷积前面，这里主要是参照在transformer中 MSA模块在MLP前面。准确度降低到79.9%同时计算量也有所下降</li>
<li><strong>Increasing the kernel size</strong>，尝试增大卷积核，最后实验表明7x7卷积核效果最好，包括在较大的ResNet-200中也是如此。在计算量几乎没有改变的情况下，准确率提高到了80.6%。</li>
</ul>
</li>
</ul>
<p><img src="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/image-20220220084241048.png" alt="image-20220220084241048"></p>
<ul>
<li><strong>Micro Design</strong>,一些微观层面的设计
<ul>
<li><strong>ReLU=&gt;GELU</strong>,准确率没变化，主要是在最新的一些transformer中用到了这种激活函数就把GELU应用到卷积网络中。（感觉作用不是很大）</li>
<li><strong>Fewer activation functions</strong>，在transformer的一个模块中除了最后的MLP中有激活函数其余均没有，因此将ResNet中除了两个1x1卷积间的激活函数外均去掉，也就是每个block只进行一次激活函数，准确率提升到了81.3%。（感觉这个trick蛮有意思的）</li>
<li><strong>Fewer normalization layers</strong>，只保留dwconv后的一个归一化层，准确率提升到81.4%</li>
<li><strong>Substituting BN with LN</strong>，用LN替代BN, BN主要是用来提高收敛速度和避免过拟合的，但是也可能会对模型的最终性能造成一定的影响。最后将所有的BN替换成LN 准确率提升到81.5%</li>
<li><strong>Separate downsampling layers</strong>，单独的下采样层。这里的修改有点没大看懂，但准确率最后来到了82.0%</li>
</ul>
</li>
</ul>
<blockquote>
<p>个人的一些想法</p>
</blockquote>
<ul>
<li>这篇文章通过效仿transformer中的一些设计和trick，通过大量实验将ResNet-50模型准确率硬生生提升了3，4个百分点，可以说是一定程度上打破了未来全部都transformer化的进程。</li>
<li>这篇文章中许多调参技巧都值得去进一步进行验证和使用</li>
</ul>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></div><div class="post_share"><div class="social-share" data-image="/2021/12/21/%E8%AE%BA%E6%96%87%E7%AE%80%E8%AE%B0%E7%B2%BE%E8%AE%B0/cover.jpeg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/04/%E6%96%B0%E6%9C%BA%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">新机环境安装指南</div></div></a></div><div class="next-post pull-right"><a href="/2021/11/17/%E5%A4%A7%E5%AD%A6%E7%BE%8E%E9%A3%9F%E6%B5%8B%E8%AF%84%E7%AF%87/"><img class="next-cover" src="/2021/11/17/%E5%A4%A7%E5%AD%A6%E7%BE%8E%E9%A3%9F%E6%B5%8B%E8%AF%84%E7%AF%87/cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大学美食测评篇</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision"><span class="toc-number">1.</span> <span class="toc-text">CLIP:Learning Transferable Visual Models From Natural Language Supervision</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ConvNeXt%EF%BC%9AA-ConvNet-for-the-2020s"><span class="toc-number">2.</span> <span class="toc-text">ConvNeXt：A ConvNet for the 2020s</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By ss967</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">陕ICP备2020017270号</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>